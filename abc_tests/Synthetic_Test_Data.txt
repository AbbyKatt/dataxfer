{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CausalityAI Test Data Generator\n",
    "#Magic synthetic data generator for testing CausalityAI\n",
    "BaseLineDS=\"Causality_BaseLine\"\n",
    "#BaseLineDS=\"CauslaitySampleData\"\n",
    "TestDS=\"Causality_Test_001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generators/Mappers\n",
    "\n",
    "def generate_uuid():\n",
    "    import uuid\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def generate_date():\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "    start_date = datetime.now() - timedelta(days=365)\n",
    "    end_date = datetime.now()\n",
    "    delta = end_date - start_date\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = random.randrange(int_delta)\n",
    "\n",
    "    #Turn data into google date format\n",
    "    return (start_date + timedelta(seconds=random_second)).strftime('%Y-%m-%d')\n",
    "\n",
    "def generateshortID():\n",
    "    import random\n",
    "    return random.randint(0, 1000000)\n",
    "def GenerateName():\n",
    "    import random\n",
    "    names=[\"John\",\"Jane\",\"Jim\",\"Jill\",\"Jack\",\"Jenny\",\"Joe\",\"William\",\"Sheera\"]\n",
    "    lastName=[\"Smith\",\"Jones\",\"Johnson\",\"Williams\",\"Brown\"]\n",
    "    return names[random.randint(0,len(names)-1)]+\" \"+lastName[random.randint(0,len(lastName)-1)]\n",
    "\n",
    "def GenerateMoney():\n",
    "    import random\n",
    "    return random.randint(0,1000000)\n",
    "\n",
    "def GenerateRecords(schema,recordCount):\n",
    "    records=[]\n",
    "    for i in range(0,recordCount):\n",
    "        record={}\n",
    "        for key in schema.keys():\n",
    "            record[key]=schema[key]()\n",
    "        records.append(record)\n",
    "    return records \n",
    "\n",
    "def GenerateRecordsOTM(schema,linkageKeys,keyName,otmCount):\n",
    "    records=[]\n",
    "    for key in linkageKeys:\n",
    "        for i in range(0,otmCount):\n",
    "            record={}\n",
    "            for field in schema.keys():\n",
    "                record[field]=schema[field]()\n",
    "            record[keyName]=key\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "def dumpSchema(name,schema,functional_category):\n",
    "    print(\"Schema for \"+name)\n",
    "    rows=[]\n",
    "    for key in schema.keys():\n",
    "        keys={\"datahub_rules\":\"\",\n",
    "        \"functional category\":functional_category,\n",
    "        \"Source Table\":name,\n",
    "        \"Target Table\":name,\n",
    "        \"Target Field\":key,\n",
    "        \"Derivation\":\"direct\"}\n",
    "        rows.append(keys)\n",
    "\n",
    "    df=pd.DataFrame(rows)\n",
    "    return df\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutator for inputs / RAFT Result Generators\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "RAFTResults=[]\n",
    "\n",
    "class RAFTResult():\n",
    "    def __init__(self,TableName,ID,ColumnName,ActualValue,ExpectedValue,DeviationReason):\n",
    "        self.TableName=TableName\n",
    "        self.ID=ID\n",
    "        self.ColumnName=ColumnName\n",
    "        self.ActualValue=ActualValue\n",
    "        self.ExpectedValue=ExpectedValue\n",
    "        self.DeviationReason=DeviationReason\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"TableName\":self.TableName,\n",
    "            \"ID\":self.ID,\n",
    "            \"ColumnName\":self.ColumnName,\n",
    "            \"ActualValue\":self.ActualValue,\n",
    "            \"ExpectedValue\":self.ExpectedValue,\n",
    "            \"DeviationReason\":self.DeviationReason\n",
    "        }\n",
    "        \n",
    "    @staticmethod\n",
    "    def CompareDataframes(baseDF, testDF, TableName, pkField):\n",
    "        # Ensure the pkField is set as the index\n",
    "        results=[]\n",
    "        if baseDF.index.name != pkField:\n",
    "            baseDF = baseDF.set_index(pkField)\n",
    "        if testDF.index.name != pkField:\n",
    "            testDF = testDF.set_index(pkField)\n",
    "        \n",
    "        # Convert DataFrames to dictionaries indexed by the index (pkField)\n",
    "        base_dict = baseDF.to_dict(orient='index')\n",
    "        test_dict = testDF.to_dict(orient='index')\n",
    "\n",
    "        # Iterate over the keys in base_dict\n",
    "        for key in base_dict.keys():\n",
    "            if key in test_dict:\n",
    "                base_record = base_dict[key]\n",
    "                test_record = test_dict[key]\n",
    "                for field in base_record:\n",
    "                    if field not in [pkField, 'CPK'] and base_record[field] != test_record.get(field):\n",
    "                        # print(f\"CPK of mismatch: {key}\")\n",
    "                        # print(f\"Expected value: {base_record[field]}, Actual value: {test_record.get(field)}\")\n",
    "                        # print(f\"TableName: {TableName}\")\n",
    "                        # print(f\"FieldName: {field}\\n\")\n",
    "                        \n",
    "                        #Create RAFTResult\n",
    "                        results.append(RAFTResult(TableName, key, field, test_record.get(field), base_record[field], \"Data mismatch\"))\n",
    "            else:\n",
    "                print(f\"Record with CPK {key} not found in testDF\")\n",
    "                #For every field (not id,CPK) in baseDF, create a RAFTResult\n",
    "                # for field in base_dict[key]:\n",
    "                #     if field not in [\"id\", 'CPK']:\n",
    "                #         results.append(RAFTResult(TableName, key, field, None, base_dict[key][field], \"Record not found in testDF\"))\n",
    "                \n",
    "        \n",
    "        # # Check for any keys in test_dict not in base_dict\n",
    "        # for key in test_dict.keys():\n",
    "        #     if key not in base_dict:\n",
    "        #         print(f\"Record with CPK {key} found in testDF but not in baseDF\")\n",
    "\n",
    "        return results\n",
    "        \n",
    "\n",
    "#Specfies a mutation at field level\n",
    "class Mutation():\n",
    "    def __init__(self,TableName,FieldName,MutatePercentage,MutateGenerator,DeviationReason):\n",
    "        self.TableName=TableName\n",
    "        self.FieldName=FieldName\n",
    "        self.MutatePercentage=MutatePercentage\n",
    "        self.MutateGenerator=MutateGenerator\n",
    "        self.DeviationReason=DeviationReason\n",
    "\n",
    "#Apply mutations across percentage of records\n",
    "def MutateInputDF(Inputdf,mutationSchema):\n",
    "    for mutation in mutationSchema:\n",
    "        for index, row in Inputdf.iterrows():\n",
    "            if random.randint(0,100)<=mutation.MutatePercentage:\n",
    "                Inputdf.at[index,mutation.FieldName]=mutation.MutateGenerator()\n",
    "                RAFTResults.append(RAFTResult(mutation.TableName,index,mutation.FieldName,Inputdf.at[index,mutation.FieldName],mutation.MutateGenerator(),mutation.DeviationReason))\n",
    "                RAFTResults.append(RAFTResult(\"in_\" + mutation.TableName,index,mutation.FieldName,Inputdf.at[index,mutation.FieldName],mutation.MutateGenerator(),mutation.DeviationReason))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_id</th>\n",
       "      <th>txn_date</th>\n",
       "      <th>txn_amount</th>\n",
       "      <th>txn_type</th>\n",
       "      <th>txn_country</th>\n",
       "      <th>flagFraudSuspected</th>\n",
       "      <th>flagSuspectTransfer</th>\n",
       "      <th>facility_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dd55578e-e381-4421-9892-cd194aa87ccc</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>806983</td>\n",
       "      <td>debit</td>\n",
       "      <td>India</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>c8f888dd-1a8a-4136-8f75-814f880f70d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>651deb7a-a3d3-43c1-bb49-81985e80f49d</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>199444</td>\n",
       "      <td>credit</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>c8f888dd-1a8a-4136-8f75-814f880f70d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>938e88cf-3937-4c7c-ad66-890504692212</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>359867</td>\n",
       "      <td>debit</td>\n",
       "      <td>UK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>c8f888dd-1a8a-4136-8f75-814f880f70d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691eee25-8586-4d91-bce5-dda681feb031</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>495787</td>\n",
       "      <td>debit</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>c8f888dd-1a8a-4136-8f75-814f880f70d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7d9053b4-57af-449f-bd6f-3361e0dbdff9</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>781295</td>\n",
       "      <td>credit</td>\n",
       "      <td>India</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>c8f888dd-1a8a-4136-8f75-814f880f70d9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 txn_id    txn_date  txn_amount txn_type  \\\n",
       "0  dd55578e-e381-4421-9892-cd194aa87ccc  2024-03-22      806983    debit   \n",
       "1  651deb7a-a3d3-43c1-bb49-81985e80f49d  2024-05-23      199444   credit   \n",
       "2  938e88cf-3937-4c7c-ad66-890504692212  2023-06-30      359867    debit   \n",
       "3  691eee25-8586-4d91-bce5-dda681feb031  2023-10-28      495787    debit   \n",
       "4  7d9053b4-57af-449f-bd6f-3361e0dbdff9  2023-08-17      781295   credit   \n",
       "\n",
       "  txn_country  flagFraudSuspected  flagSuspectTransfer  \\\n",
       "0       India               False                 True   \n",
       "1         USA               False                 True   \n",
       "2          UK               False                False   \n",
       "3         USA               False                 True   \n",
       "4       India               False                False   \n",
       "\n",
       "                            facility_id  \n",
       "0  c8f888dd-1a8a-4136-8f75-814f880f70d9  \n",
       "1  c8f888dd-1a8a-4136-8f75-814f880f70d9  \n",
       "2  c8f888dd-1a8a-4136-8f75-814f880f70d9  \n",
       "3  c8f888dd-1a8a-4136-8f75-814f880f70d9  \n",
       "4  c8f888dd-1a8a-4136-8f75-814f880f70d9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Layer A - randomly generated data only (input layers)\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "writetoBQ=True\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "#Generate AccountDetails\n",
    "#------------------------------------------------------------------------------------\n",
    "schemaAccountDetails={\n",
    "    \"account_id\":generate_uuid,\n",
    "    \"account_open_date\":generate_date,\n",
    "    \"branch_code\":generateshortID,\n",
    "    \"customer_name\":GenerateName,\n",
    "    \"account_type\":lambda: random.choice([\"basic\", \"premium\", \"gold\",\"business\"]),\n",
    "    \"Defaulted\":lambda: random.choice([True,False,False,False,False,False,False]),\n",
    "    \"CreditRiskBand\":lambda: random.choice([\"A\", \"B\", \"C\",\"D\",\"E\"]),\n",
    "    \"flagPEPExposed\":lambda: random.choice([True,False,False,False,False,False,False,False]),\n",
    "    \"flagHighRiskCountry\":lambda: random.choice([True,False,False,False,False,False])\n",
    "}\n",
    "\n",
    "#if account_type=\"gold\" and account_open_date > 2020-01-01 then \"goldstar\" else account_type\n",
    "\n",
    "dfAccount=pd.DataFrame(GenerateRecords(schemaAccountDetails,10))\n",
    "if writetoBQ:\n",
    "    dfAccount.to_gbq(BaseLineDS+\".in_AccountDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfAccount.to_gbq(BaseLineDS+\".AccountDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "account_ids=dfAccount[\"account_id\"]\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "#Generate FacDetails\n",
    "#------------------------------------------------------------------------------------\n",
    "schemaFacilityDetails={\n",
    "    \"facility_id\":generate_uuid,\n",
    "    \"facility_product\":lambda: random.choice([\"loan\", \"credit card\", \"debit card\"]),\n",
    "    \"facility_type\":lambda: random.choice([\"retail\", \"corporate\"]),\n",
    "    \"facility_limit\":GenerateMoney,\n",
    "    \"facility_open_date\":generate_date, #Bug #1 - facility generated _before_ account ID\n",
    "    \"facility_country\":lambda: random.choice([\"USA\", \"UK\", \"India\",\"Canada\"]),\n",
    "    \"account_id\":lambda: random.choice(account_ids),\n",
    "    \"Past_Due60Day\":lambda: random.choice([True,False,False,False,False,False]),\n",
    "    \"RepoTermsAgreed\":lambda: random.choice([True,False,False,False,False,False]),\n",
    "    \"flagSanctionedEntity\":lambda: random.choice([True,False,False,False,False,False]),\n",
    "    \"flagUnusualActivity\":lambda: random.choice([True,False,False,False,False,False]),\n",
    "    \"flagHighRiskIndustry\":lambda: random.choice([True,False,False,False])\n",
    "}\n",
    "\n",
    "dfFacility=pd.DataFrame(GenerateRecordsOTM(schemaFacilityDetails,account_ids,\"account_id\",3))                       \n",
    "if writetoBQ:\n",
    "    dfFacility.to_gbq(BaseLineDS+\".in_FacilityDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfFacility.to_gbq(BaseLineDS+\".FacilityDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "facility_ids=dfFacility[\"facility_id\"]\n",
    "#------------------------------------------------------------------------------------\n",
    "#Generate TxnDetails\n",
    "#------------------------------------------------------------------------------------\n",
    "scemaTxnDetails={\n",
    "    \"txn_id\":generate_uuid,\n",
    "    \"txn_date\":generate_date,\n",
    "    \"txn_amount\":GenerateMoney,\n",
    "    \"txn_type\":lambda: random.choice([\"credit\", \"debit\"]),\n",
    "    \"txn_country\":lambda: random.choice([\"USA\", \"UK\", \"India\",\"Canada\"]),\n",
    "    \"flagFraudSuspected\":lambda: random.choice([True,False,False,False,False,False]),\n",
    "    \"flagSuspectTransfer\":lambda: random.choice([True,False,False,False,False,False])\n",
    "}\n",
    "\n",
    "dfTxn=pd.DataFrame(GenerateRecordsOTM(scemaTxnDetails,facility_ids,\"facility_id\",10))\n",
    "if writetoBQ:\n",
    "    dfTxn.to_gbq(BaseLineDS+\".in_TxnDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfTxn.to_gbq(BaseLineDS+\".TxnDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "dfTxn.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Mutate Layer A to create TestSet - using Mutator\n",
    "\n",
    "AccountMutations=[Mutation(\"AccountDetails\",\"branch_code\",10,lambda: random.choice([0000,6667,1234]),\"Value Mismatch\"),\n",
    "                  Mutation(\"AccountDetails\",\"account_type\",10,lambda: random.choice([\"basic\", \"premium\", \"gold\",\"business\"]),\"Value Mismatch\")]\n",
    "\n",
    "MutateInputDF(dfAccount,AccountMutations)\n",
    "#dfAccount\n",
    "\n",
    "FacilityMutations=[ Mutation(\"FacilityDetails\",\"facility_type\",20,generate_uuid,\"Invalid Value\"),\n",
    "                    Mutation(\"FacilityDetails\",\"facility_limit\",20,GenerateMoney,\"Aggregate Mismatch\"),\n",
    "                    Mutation(\"FacilityDetails\",\"account_id\",10,lambda: None,\"CONTAINS NULLS\")]\n",
    "MutateInputDF(dfFacility,FacilityMutations)\n",
    "#dfFacility                \n",
    "    \n",
    "TransactionMutations=[ Mutation(\"TxnDetails\",\"txn_type\",20,lambda: random.choice([\"basic\", \"premium\", \"gold\",\"business\"]),\"Value Mismatch\")]\n",
    "MutateInputDF(dfTxn,TransactionMutations)\n",
    "#dfTxn\n",
    "\n",
    "#Write to Test Dataset\n",
    "if writetoBQ:\n",
    "    dfAccount.to_gbq(TestDS+\".in_AccountDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfFacility.to_gbq(TestDS+\".in_FacilityDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfTxn.to_gbq(TestDS+\".in_TxnDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfAccount.to_gbq(TestDS+\".AccountDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfFacility.to_gbq(TestDS+\".FacilityDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfTxn.to_gbq(TestDS+\".TxnDetails\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for AccountDetails\n",
      "Schema for FacilityDetails\n",
      "Schema for TxnDetails\n"
     ]
    }
   ],
   "source": [
    "# #Dump Layer A\n",
    "df=dumpSchema(\"AccountDetails\",schemaAccountDetails,\"ingestion\")\n",
    "df.to_csv(\"AccountDetails.csv\",index=False)\n",
    "df=dumpSchema(\"FacilityDetails\",schemaFacilityDetails,\"ingestion\")\n",
    "df.to_csv(\"FacilityDetails.csv\",index=False)\n",
    "df=dumpSchema(\"TxnDetails\",scemaTxnDetails,\"ingestion\")\n",
    "df.to_csv(\"TxnDetails.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x0000029A1B7909D0>\n",
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x0000029A4E0C1040>\n",
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x0000029A1B8CE4C0>\n"
     ]
    }
   ],
   "source": [
    "#Create source code views\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def CreateBQView(src):\n",
    "    client = bigquery.Client(project=\"datawx\")\n",
    "    job = client.query(src)\n",
    "    print(job.result())\n",
    "\n",
    "def CreateSourceCodeView(dataset,inputTable,inputAlias,schema,outputTable):\n",
    "    str=f\"--Source Code for view to produce [{outputTable}] table\\n\"\n",
    "    str+=f\"CREATE OR REPLACE VIEW {dataset}.src_{outputTable} AS\\n\"\n",
    "    str+=\"SELECT\\n\"\n",
    "    for key in schema.keys():\n",
    "        str+=\"\\t\" + inputAlias + \".\" + key+\" AS \"+key+\",\\n\"\n",
    "        #print(\"\\t\" + inputAlias + \".\" + key+\" AS \"+key+\",\\n\")\n",
    "    str+=\"FROM \"+inputTable + \" as \" + inputAlias+\";\"\n",
    "    #print(str)\n",
    "    return str\n",
    "\n",
    "\n",
    "\n",
    "#Build source code for views\n",
    "srcAccountDetails=CreateSourceCodeView(BaseLineDS,BaseLineDS+\".in_AccountDetails\",\"AcctDetails\",schemaAccountDetails,\"AccountDetails\")\n",
    "srcFacilityDetails=CreateSourceCodeView(BaseLineDS,BaseLineDS+\".in_FacilityDetails\",\"FacDetails\",schemaFacilityDetails,\"FacilityDetails\")\n",
    "srcTxnDetails=CreateSourceCodeView(BaseLineDS,BaseLineDS+\".in_TxnDetails\",\"TxnDetails\",scemaTxnDetails,\"TxnDetails\")\n",
    "CreateBQView(srcAccountDetails)\n",
    "CreateBQView(srcFacilityDetails)\n",
    "CreateBQView(srcTxnDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Source Code for view to produce [TxnDetails] table\n",
      "CREATE OR REPLACE VIEW CauslaitySampleData.src_TxnDetails AS\n",
      "SELECT\n",
      "\tTxnDetails.txn_id AS txn_id,\n",
      "\tTxnDetails.txn_date AS txn_date,\n",
      "\tTxnDetails.txn_amount AS txn_amount,\n",
      "\tTxnDetails.txn_type AS txn_type,\n",
      "\tTxnDetails.txn_country AS txn_country,\n",
      "FROM CauslaitySampleData.in_TxnDetails as TxnDetails;\n"
     ]
    }
   ],
   "source": [
    "print(srcTxnDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Layer B - SQL joins of 3 tables to create 2 tables\n",
    "def getAccount_FacilitySQL(DataSet):\n",
    "  Account_FacilitySQL=f\"\"\"\n",
    "  SELECT\n",
    "    a.account_id as id,\n",
    "    CONCAT(CAST(a.account_id AS STRING), \"/\", CAST(f.facility_id AS STRING)) AS CPK,\n",
    "    a.account_id,\n",
    "    a.account_open_date,\n",
    "    a.branch_code,\n",
    "    a.customer_name,\n",
    "    a.account_type,   \n",
    "    a.flagPEPExposed,\n",
    "    a.flagHighRiskCountry,\n",
    "  \n",
    "    CASE \n",
    "        WHEN a.account_type = 'gold' AND a.account_open_date > '2020-01-01' THEN 'goldstar'\n",
    "        ELSE account_type\n",
    "    END AS old_account_type,    \n",
    "    f.facility_id,\n",
    "    f.facility_product,\n",
    "    f.facility_type,\n",
    "    f.facility_limit,\n",
    "    f.facility_open_date,\n",
    "    f.facility_country,\n",
    "    f.flagSanctionedEntity,\n",
    "    f.flagUnusualActivity,\n",
    "    f.flagHighRiskIndustry,\n",
    "\n",
    "    --Calculate Risk Band\n",
    "    CASE \n",
    "        WHEN f.RepoTermsAgreed THEN \"RepoTermsAgreed\"\n",
    "        WHEN f.Past_Due60Day THEN \"PastDue\"\n",
    "        WHEN a.Defaulted THEN \"Defaulted\"\n",
    "        ELSE a.CreditRiskBand\n",
    "    END AS CalcRiskBand\n",
    "    \n",
    "    \n",
    "  FROM\n",
    "    {DataSet}.AccountDetails a\n",
    "  JOIN\n",
    "    {DataSet}.FacilityDetails f\n",
    "  ON\n",
    "    a.account_id = f.account_id\n",
    "    order by a.account_id\n",
    "  \"\"\"\n",
    "  return Account_FacilitySQL\n",
    "\n",
    "dfAccountFacility_Base=pd.read_gbq(getAccount_FacilitySQL(BaseLineDS),project_id=\"datawx\")\n",
    "dfAccountFacility_Test=pd.read_gbq(getAccount_FacilitySQL(TestDS),project_id=\"datawx\")\n",
    "\n",
    "if writetoBQ:\n",
    "    dfAccountFacility_Base.to_gbq(BaseLineDS+\".Account_Facility\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfAccountFacility_Test.to_gbq(TestDS+\".Account_Facility\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "#Generate Facility_Txn\n",
    "#------------------------------------------------------------------------------------\n",
    "def getFacility_TxnSQL(Dataset):\n",
    "  Facility_TxnSQL=f\"\"\"\n",
    "  SELECT \n",
    "    FD.facility_id as id,\n",
    "    CONCAT(CAST(FD.facility_id AS STRING), \"/\", CAST(TD.txn_id AS STRING)) AS CPK,\n",
    "    FD.facility_id,\n",
    "    FD.facility_product,\n",
    "    FD.facility_type,\n",
    "    FD.facility_limit,\n",
    "    FD.facility_open_date,\n",
    "    FD.facility_country,\n",
    "    FD.account_id,\n",
    "    TD.txn_id,\n",
    "    TD.txn_date,\n",
    "    TD.txn_amount,\n",
    "    TD.txn_type,\n",
    "    TD.txn_country,\n",
    "    TD.flagFraudSuspected,\n",
    "    TD.flagSuspectTransfer\n",
    "\n",
    "  FROM \n",
    "    {Dataset}.FacilityDetails FD\n",
    "  INNER JOIN \n",
    "    {Dataset}.TxnDetails TD\n",
    "  ON \n",
    "    FD.facility_id = TD.facility_id;\n",
    "  \"\"\"\n",
    "  return Facility_TxnSQL\n",
    "\n",
    "dfFacilityTxn_Base=pd.read_gbq(getFacility_TxnSQL(BaseLineDS),project_id=\"datawx\")\n",
    "dfFacilityTxn_Test=pd.read_gbq(getFacility_TxnSQL(TestDS),project_id=\"datawx\")\n",
    "\n",
    "if writetoBQ:\n",
    "    dfFacilityTxn_Base.to_gbq(BaseLineDS+\".Facility_Txn\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfFacilityTxn_Test.to_gbq(TestDS+\".Facility_Txn\",project_id=\"datawx\",if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x0000029A509BA430>\n",
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x0000029A1B8E2400>\n"
     ]
    }
   ],
   "source": [
    "#Turn SQL into source code view\n",
    "def SQLtoView(dataSet,viewName,selectSQL):\n",
    "    str=f\"--Source Code for view to produce [{viewName}] table\\n\"\n",
    "    str+=f\"CREATE OR REPLACE VIEW {dataSet}.src_{viewName} AS\\n\"\n",
    "    str+=selectSQL\n",
    "    return str\n",
    "\n",
    "srcAccount_Facility=SQLtoView(BaseLineDS,\"Account_Facility\",getAccount_FacilitySQL(BaseLineDS))\n",
    "srcFacility_Txn=SQLtoView(BaseLineDS,\"Facility_Txn\",getFacility_TxnSQL(BaseLineDS))\n",
    "\n",
    "#print(srcAccount_Facility)\n",
    "#print(srcFacility_Txn)\n",
    "CreateBQView(srcAccount_Facility)\n",
    "CreateBQView(srcFacility_Txn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Layer C\n",
    "#DELIB-BUG!!!  AVG(A.facility_limit) AS summed_facility_limit << should be summed!\n",
    "#this is intentional so we have something fro the AI to do\n",
    "def getAccountUsageSQL(Dataset):\n",
    "  AccountUsageSQL=f\"\"\"SELECT\n",
    "    A.account_id as id,\n",
    "    A.account_id,\n",
    "    CAST(A.account_id AS STRING) AS CPK,\n",
    "    A.account_open_date,\n",
    "    A.branch_code,\n",
    "    A.customer_name,\n",
    "    A.account_type,\n",
    "    A.old_account_type,\n",
    "    AVG(A.facility_limit) AS summed_facility_limit,\n",
    "    SUM(T.txn_amount) AS summed_txn_amount,\n",
    "    \n",
    "    --AccountReviewRequired/AccountLocked Logic\n",
    "    MAX(A.flagPEPExposed OR A.flagUnusualActivity OR A.flagSanctionedEntity OR T.flagFraudSuspected OR T.flagSuspectTransfer) AS AccountReviewRequired,\n",
    "    MAX(A.flagUnusualActivity OR T.flagFraudSuspected  OR T.flagSuspectTransfer ) AS AccountLocked,\n",
    "    \n",
    "    A.CalcRiskBand, \n",
    " \n",
    "  FROM\n",
    "    `{Dataset}.Account_Facility` A\n",
    "  JOIN\n",
    "    `{Dataset}.Facility_Txn` T\n",
    "  ON\n",
    "    A.facility_id = T.facility_id\n",
    "  GROUP BY\n",
    "    A.account_id,\n",
    "    A.account_open_date,\n",
    "    A.branch_code,\n",
    "    A.customer_name,\n",
    "    A.account_type,\n",
    "    A.old_account_type,\n",
    "    A.CalcRiskBand\n",
    "  \"\"\"\n",
    "  return AccountUsageSQL\n",
    "\n",
    "\n",
    "dfAccountUsage_Base=pd.read_gbq(getAccountUsageSQL(BaseLineDS),project_id=\"datawx\")\n",
    "dfAccountUsage_Test=pd.read_gbq(getAccountUsageSQL(TestDS),project_id=\"datawx\")\n",
    "if writetoBQ:\n",
    "    dfAccountUsage_Base.to_gbq(BaseLineDS+\".AccountUsage\",project_id=\"datawx\",if_exists=\"replace\")\n",
    "    dfAccountUsage_Test.to_gbq(TestDS+\".AccountUsage\",project_id=\"datawx\",if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Source Code for view to produce [AccountUsage] table\n",
      "CREATE OR REPLACE VIEW Causality_BaseLine.src_AccountUsage AS\n",
      "SELECT\n",
      "    A.account_id as id,\n",
      "    A.account_id,\n",
      "    CAST(A.account_id AS STRING) AS CPK,\n",
      "    A.account_open_date,\n",
      "    A.branch_code,\n",
      "    A.customer_name,\n",
      "    A.account_type,\n",
      "    A.old_account_type,\n",
      "    AVG(A.facility_limit) AS summed_facility_limit,\n",
      "    SUM(T.txn_amount) AS summed_txn_amount,\n",
      "    \n",
      "    --AccountReviewRequired/AccountLocked Logic\n",
      "    MAX(A.flagPEPExposed OR A.flagUnusualActivity OR A.flagSanctionedEntity OR T.flagFraudSuspected OR T.flagSuspectTransfer) AS AccountReviewRequired,\n",
      "    MAX(A.flagUnusualActivity OR T.flagFraudSuspected  OR T.flagSuspectTransfer ) AS AccountLocked \n",
      " \n",
      "  FROM\n",
      "    `Causality_BaseLine.Account_Facility` A\n",
      "  JOIN\n",
      "    `Causality_BaseLine.Facility_Txn` T\n",
      "  ON\n",
      "    A.facility_id = T.facility_id\n",
      "  GROUP BY\n",
      "    A.account_id,\n",
      "    A.account_open_date,\n",
      "    A.branch_code,\n",
      "    A.customer_name,\n",
      "    A.account_type,\n",
      "    A.old_account_type\n",
      "  \n",
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x0000029A50950550>\n"
     ]
    }
   ],
   "source": [
    "#Turn SQL into source code view\n",
    "srcAccountUsage=SQLtoView(BaseLineDS,\"AccountUsage\",getAccountUsageSQL(BaseLineDS))\n",
    "print(srcAccountUsage)\n",
    "CreateBQView(srcAccountUsage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record with CPK 3e628be3-a492-456b-b8e4-519ed54af055/eb763996-72df-4d17-9e7c-f739d0c2c08e not found in testDF\n",
      "Record with CPK ad6ce14e-cc75-468f-936c-56d9d931899c/6ac3f1e6-b39d-45a2-ae74-2cf1939f4189 not found in testDF\n",
      "Record with CPK e1c74641-9bfc-4a36-844c-36f826438992/ee9229cd-59ee-4ec9-8ed0-c6d9dc79de5f not found in testDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Compare Layer B and C across BaseLine and Test / Write RAFT Results\n",
    "#RAFTResults=[]\n",
    "ret=RAFTResult.CompareDataframes(dfAccountFacility_Base,dfAccountFacility_Test,\"Account_Facility\",\"CPK\")\n",
    "for err in ret:\n",
    "    RAFTResults.append(err)\n",
    "\n",
    "# json=[x.to_dict() for x in ret]\n",
    "# dfRet=pd.DataFrame(json)\n",
    "# dfRet\n",
    "\n",
    "ret=RAFTResult.CompareDataframes(dfFacilityTxn_Base,dfFacilityTxn_Test,\"Facility_Txn\",\"CPK\")\n",
    "for err in ret:\n",
    "    RAFTResults.append(err)\n",
    "\n",
    "\n",
    "# # json=[x.to_dict() for x in ret]\n",
    "# # dfRet=pd.DataFrame(json)\n",
    "# # dfRet\n",
    "\n",
    "\n",
    "ret=RAFTResult.CompareDataframes(dfAccountUsage_Base,dfAccountUsage_Test,\"AccountUsage\",\"CPK\")\n",
    "for err in ret:\n",
    "    RAFTResults.append(err)\n",
    "\n",
    "\n",
    "#Turn RAFTResults into a dataframe\n",
    "raftJSON=[x.to_dict() for x in RAFTResults]\n",
    "dfRAFTResults=pd.DataFrame(raftJSON)\n",
    "dfRAFTResults = dfRAFTResults.astype(str)\n",
    "dfRAFTResults\n",
    "\n",
    "#Write RAFTResults to BigQuery\n",
    "if writetoBQ:\n",
    "    dfRAFTResults.to_gbq(BaseLineDS+\".RAFTResults\",project_id=\"datawx\",if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x000001A021D7B2B0>\n"
     ]
    }
   ],
   "source": [
    "#Create errors view\n",
    "CreateErrorsSQL=f\"\"\"\n",
    "create or replace view {BaseLineDS}.vw_Errors as\n",
    "SELECT TableName,\n",
    "ColumnName,\n",
    "count(*) as CountError\n",
    "FROM {BaseLineDS}.RAFTResults\n",
    "group by TableName,ColumnName\n",
    "order by TableName,ColumnName\"\"\"\n",
    "\n",
    "if writetoBQ:\n",
    "    CreateBQView(CreateErrorsSQL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
